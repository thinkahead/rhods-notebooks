{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bc3ea-4ce3-49bf-bb1f-e209de8ca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
    "from codeflare_sdk.cluster.auth import TokenAuthentication\n",
    "from codeflare_sdk.job.jobs import DDPJobDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614daa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication object for oc user permissions\n",
    "auth = TokenAuthentication(\n",
    "    token = \"sha256~2CRnJ7Tef3nTsAlWowaedwCUcc4lLswrNtpoLnON6F4\",\n",
    "    server = \"https://api.mini2.mydomain.com:6443\",\n",
    "    skip_tls=True\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27f84c",
   "metadata": {},
   "source": [
    "Here, we want to define our cluster by specifying the resources we require for our batch workload. Below, we define our cluster object (which generates a corresponding AppWrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bc870-091f-4e11-9642-cba145710159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our cluster and submit appwrapper (reduce specs as desired)\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='mnisttest',\n",
    "    namespace='batch-mnist',\n",
    "    image=\"quay.io/thinkahead/base:ray2.1.0-py38-gpu-pytorch1.12.0cu117-20230419-1\",\n",
    "    min_worker=2,\n",
    "    max_worker=3,\n",
    "    min_cpus=8,\n",
    "    max_cpus=8,\n",
    "    min_memory=16,\n",
    "    max_memory=16,\n",
    "    gpu=1,\n",
    "    instascale=False # Can be set to false if scaling not needed\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eef53c",
   "metadata": {},
   "source": [
    "Next, we want to bring our cluster up, so we call the `up()` function below to submit our cluster AppWrapper yaml onto the MCAD queue, and begin the process of obtaining our resource cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0884bbc-c224-4ca0-98a0-02dfa09c2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring up the cluster\n",
    "cluster.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ebdfb",
   "metadata": {},
   "source": [
    "Now, we want to check on the status of our resource cluster, and wait until it is finally ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b4311-2e61-44c9-8225-87c2db11363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a55fe4",
   "metadata": {},
   "source": [
    "Let's quickly verify that the specs of the cluster are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd45bc5-03c0-4ae5-9ec5-dd1c30f1a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2c9b3",
   "metadata": {},
   "source": [
    "Now that our resource cluster is ready, we can directly submit our batch job (model training on three workers with 1 gpu each) to the cluster via torchx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6ccd6-a17e-413a-a0e4-65004fc35463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobdef = DDPJobDefinition(\n",
    "    name=\"mnisttest\",\n",
    "    script=\"mnist_fashion.py\",\n",
    "    #scheduler_args={\"requirements\": \"requirements.txt\"}\n",
    ")\n",
    "job = jobdef.submit(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff065051",
   "metadata": {},
   "source": [
    "Now we can go ahead and look at the status and logs of our batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0b0da-c22e-4142-b096-407ac8aebe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c1809-de72-4acf-b0f6-e67d345640f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8cd32",
   "metadata": {},
   "source": [
    "Finally, we bring our resource cluster down and release/terminate the associated resources, bringing everything back to the way it was before our cluster was brought up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36db0f-31f6-4373-9503-dc3c1c4c3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39a92f-a2d8-4ff2-b960-4aacba121251",
   "metadata": {},
   "source": [
    "# Fetch the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0adb2-f22b-411f-84a2-9b4534192aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b9443-c626-41a0-9686-44bdd217be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "X, y = fetch_openml('Fashion-MNIST', return_X_y=True, parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce3bdd-a925-45b0-af7b-e3657e771261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3f00f-b5a8-47f0-9742-83e43bf03b6b",
   "metadata": {},
   "source": [
    "# Draw few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d06cf1-f1ce-46d6-8d79-36c308ecb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# build a dictionary for easy access to object classes\n",
    "objects = {0: 'T-shirt/top',\n",
    "           1: 'Trouser',\n",
    "           2: 'Pullover',\n",
    "           3: 'Dress',\n",
    "           4: 'Coat',\n",
    "           5: 'Sandal',\n",
    "           6: 'Shirt',\n",
    "           7: 'Sneaker',\n",
    "           8: 'Bag',\n",
    "           9: 'Ankle boot'}\n",
    "# let's have a quick look of those images\n",
    "f, axes = plt.subplots(2, 4)\n",
    "for row in axes:\n",
    "    for axe in row:\n",
    "        index = np.random.randint(10000)\n",
    "        img = np.array(X.iloc[index, 0:]).reshape((28, 28))\n",
    "        obj = X.iloc[index, 0]\n",
    "        axe.imshow(img, cmap='gray')\n",
    "        axe.set_title(objects[obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518571c5-f9c3-48f6-a413-bf1fe1e7cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "plotX=X.loc[0:8].values.reshape(9,28,28)\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(plotX[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3dd032-f906-4a95-94bc-c47ab969d0fc",
   "metadata": {},
   "source": [
    "# Load the onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157aad9-3da1-4c93-ac1f-6d3182356c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name='mnist1' # torch.onnx.export\n",
    "#model_name='mnist2' # Pytorch Lightning model.to_onnx\n",
    "model_name='mnist3' # torch.onnx.export with batch\n",
    "#model_name='mnist4' # Pytorch Lightning model.to_onnx with batch\n",
    "\n",
    "model_file_name=model_name+\".onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db22506-bb64-4e68-b819-b3a40efef834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import numpy as np\n",
    "session = onnxruntime.InferenceSession(model_file_name, None, providers=['CPUExecutionProvider'])\n",
    "input_name = session.get_inputs()[0].name\n",
    "print(\"input name\", input_name)\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "print(\"input shape\", input_shape)\n",
    "input_type = session.get_inputs()[0].type\n",
    "print(\"input type\", input_type)\n",
    "print([i.name for i in session.get_outputs()])\n",
    "output_name = session.get_outputs()[0].name\n",
    "print(\"output name\", output_name)\n",
    "output_shape = session.get_outputs()[0].shape\n",
    "print(\"output shape\", output_shape)\n",
    "output_type = session.get_outputs()[0].type\n",
    "print(\"output type\", output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9d31a-d72b-4149-96f4-b757bdb010a1",
   "metadata": {},
   "source": [
    "# Batch request shape (batch_size,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0cd67-863d-4d4f-9cc6-15abb9fd264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=X[0:5]\n",
    "actual=y[0:5]\n",
    "arr=np.array(batch)\n",
    "result = session.run([i.name for i in session.get_outputs()], {input_name:(arr.reshape(len(batch),1,28,28).astype(np.float32))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acd7b2-0ae2-4ebd-b5bf-d598bc0a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(result[0],axis=1),actual.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a103da-571d-446e-a930-8f209c1ec8f1",
   "metadata": {},
   "source": [
    "# Single request shape (1,1,28,28) - Loop through 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646210-4ad0-4f57-9221-549e06e24fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count=0\n",
    "#for i in X.index:\n",
    "for i in range(10000):\n",
    "    arr=np.array(X.iloc[i])\n",
    "    result = session.run([i.name for i in session.get_outputs()], {input_name:(arr.reshape(1,*input_shape[1:]).astype(np.float32))})\n",
    "    expected=int(y.iloc[i])\n",
    "    actual=np.argmax(result)\n",
    "    if actual!=expected: count+=1\n",
    "    #print(\"Expected\",expected,\"Actual\",actual==expected)\n",
    "print('Accuracy:',(1-count/len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce11f75-50b4-4833-84a7-2ae08dcc7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes of fashion mnist dataset\n",
    "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "# plotting the results\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "for imagenum in range(20):\n",
    "    arr=np.array(X.iloc[imagenum])\n",
    "    result = session.run([i.name for i in session.get_outputs()], {input_name:(arr.reshape(1,*input_shape[1:]).astype(np.float32))})\n",
    "    expected=int(y.iloc[imagenum])\n",
    "    actual=np.argmax(result)\n",
    "    ax = fig.add_subplot(2, 10, imagenum+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.array(X.iloc[imagenum, 0:]).reshape((28, 28)))\n",
    "    ax.set_title(\"{} ({})\".format(classes[expected], classes[actual]),\n",
    "                 color=(\"green\" if expected==actual else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560e45f-e718-4f6b-8463-37a7236435dc",
   "metadata": {},
   "source": [
    "# Copy onnx model to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ceef17-48fc-4fcc-89bf-971b9cafa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from boto3 import session\n",
    "key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "session = boto3.session.Session(aws_access_key_id=key_id, aws_secret_access_key=secret_key)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=key_id, aws_secret_access_key=secret_key,endpoint_url=endpoint_url,verify=False)\n",
    "buckets=s3_client.list_buckets()\n",
    "for bucket in buckets['Buckets']: print(bucket['Name'])\n",
    "s3_client.upload_file(model_file_name, bucket['Name'],model_file_name)\n",
    "[item.get(\"Key\") for item in s3_client.list_objects_v2(Bucket=bucket['Name']).get(\"Contents\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af937768-f71d-49fd-bb49-068f2d427361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from boto3 import session\n",
    "key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "session = boto3.session.Session(aws_access_key_id=key_id, aws_secret_access_key=secret_key)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=key_id, aws_secret_access_key=secret_key,endpoint_url=endpoint_url,verify=False)\n",
    "buckets=s3_client.list_buckets()\n",
    "s3_client.upload_file(model_name+\"/\"+model_name+\".bin\", bucket['Name'],\"mymodel/\"+model_name+\".bin\")\n",
    "s3_client.upload_file(model_name+\"/\"+model_name+\".xml\", bucket['Name'],\"mymodel/\"+model_name+\".xml\")\n",
    "[item.get(\"Key\") for item in s3_client.list_objects_v2(Bucket=bucket['Name']).get(\"Contents\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fd588-8f58-417c-906e-c5a1e8e08fdb",
   "metadata": {},
   "source": [
    "Deploy the model in your Data Science project using RHODS UI under \"Models and model servers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697e7f6-86d6-4810-a0be-25f3bd9ad3cb",
   "metadata": {},
   "source": [
    "# Submit HTTP REST request to the ModelMesh for single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56387f1d-26b0-4b0c-b774-7a68c3123db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mnist1\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "URL='http://modelmesh-serving.huggingface.svc.cluster.local:8008/v2/models/'+model_name+'/infer' # underscore characters are removed\n",
    "headers = {}\n",
    "payload = {\n",
    "        \"inputs\": [{ \"name\": \"input_0\", \"shape\": (1,1,28,28), \"datatype\": \"FP32\", \"data\": X.iloc[0].values.tolist()}]\n",
    "    }\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "res = requests.post(URL, json=payload, headers=headers)\n",
    "print(res)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9bfe1-5600-4571-82f8-3938159592a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected\",y.iloc[0],\"Actual\",np.argmax(res.json()['outputs'][0]['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a497a8-f137-4f0b-9227-0e72a1f8a0fc",
   "metadata": {},
   "source": [
    "# Submit HTTP REST request to the ModelMesh for a batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988c792-d0f4-451d-8254-bbd7cd0846b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mymodel\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "URL='http://modelmesh-serving.huggingface.svc.cluster.local:8008/v2/models/'+model_name+'/infer' # underscore characters are removed\n",
    "headers = {}\n",
    "payload = {\n",
    "        \"inputs\": [{ \"name\": \"input_0\", \"shape\": (5,1,28,28), \"datatype\": \"FP32\", \"data\": X.loc[0:4].values.flatten().tolist()}]\n",
    "    }\n",
    "#print(payload)\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "res = requests.post(URL, json=payload, headers=headers)\n",
    "print(res)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb8ec0-43b5-46a7-b6b3-d07908454528",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y[0:5].values.tolist()\n",
    "expected=np.argmax(np.array(res.json()['outputs'][0]['data']).reshape(res.json()['outputs'][0]['shape']),axis=1)\n",
    "print(actual,expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd1cda-cd29-4ac9-9dae-54176017feaa",
   "metadata": {},
   "source": [
    "# Submit gRPC request to the ModelMesh for single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786bde3-5d60-45ca-b1a2-fec960fa8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grpcio grpcio-tools==1.46.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8847d-96cd-447e-9ab3-1eb2e76cb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/kserve/kserve/master/docs/predict-api/v2/grpc_predict_v2.proto\n",
    "!wget https://raw.githubusercontent.com/kserve/modelmesh-serving/main/fvt/proto/kfs_inference_v2.proto\n",
    "!python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. ./kfs_inference_v2.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931779a8-4538-4150-acf4-b2e2a7a8dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mnist1\" # mnist2, mnist3, mnist4\n",
    "payload = { \"model_name\": model_name,\n",
    "            \"inputs\": [{ \"name\": \"input_0\", \"shape\": (1,1,28,28), \"datatype\": \"FP32\", \"contents\": {\"fp32_contents\":X.iloc[0].values.tolist()}}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b108a8-a0b6-4f27-80b3-bede2e8aca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import kfs_inference_v2_pb2, kfs_inference_v2_pb2_grpc\n",
    "grpc_url=\"modelmesh-serving.huggingface.svc.cluster.local:8033\"\n",
    "request=kfs_inference_v2_pb2.ModelInferRequest(model_name=model_name,inputs=payload[\"inputs\"])\n",
    "grpc_channel = grpc.insecure_channel(grpc_url)\n",
    "grpc_stub = kfs_inference_v2_pb2_grpc.GRPCInferenceServiceStub(grpc_channel)\n",
    "response = grpc_stub.ModelInfer(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e43d0-15ae-43e8-bd9f-80f1a0b14c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(response.outputs),type(response.raw_output_contents))\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "d = MessageToDict(response.outputs[0])\n",
    "print(d)\n",
    "binary_data=bytes([x for x in response.raw_output_contents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41708894-c834-4cf1-ae5b-d8f4b7ed8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import base64\n",
    "FLOAT = 'f'\n",
    "fmt = '<' + FLOAT * (len(binary_data) // struct.calcsize(FLOAT))\n",
    "print(\"Expected\",y.iloc[0],\"Actual\",np.argmax(np.array(struct.unpack(fmt, binary_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33c02a-cd26-409a-be93-0a84b9c4c2e0",
   "metadata": {},
   "source": [
    "# Submit gRPC request to the ModelMesh for batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc5f15-6032-45fe-9d5a-486980a0f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mnist3\"  # mnist4\n",
    "payload = { \"model_name\": model_name,\n",
    "            \"inputs\": [{ \"name\": \"input_0\", \"shape\": (5,1,28,28), \"datatype\": \"FP32\", \"contents\": {\"fp32_contents\":X.loc[0:4].values.flatten().tolist()}}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba68ed-2f24-4095-963b-687c04bfcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import kfs_inference_v2_pb2, kfs_inference_v2_pb2_grpc\n",
    "grpc_url=\"modelmesh-serving.huggingface.svc.cluster.local:8033\"\n",
    "request=kfs_inference_v2_pb2.ModelInferRequest(model_name=model_name,inputs=payload[\"inputs\"])\n",
    "grpc_channel = grpc.insecure_channel(grpc_url)\n",
    "grpc_stub = kfs_inference_v2_pb2_grpc.GRPCInferenceServiceStub(grpc_channel)\n",
    "response = grpc_stub.ModelInfer(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84757e-dc33-4552-858f-83d1d1b3ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(response.outputs),type(response.raw_output_contents))\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "d = MessageToDict(response.outputs[0])\n",
    "print(d)\n",
    "binary_data=bytes([x for x in response.raw_output_contents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36350206-bdd9-485f-9d8b-77246007fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import base64\n",
    "FLOAT = 'f'\n",
    "fmt = '<' + FLOAT * (len(binary_data) // struct.calcsize(FLOAT))\n",
    "numbers = [str(n) for n in np.argmax(np.array(struct.unpack(fmt, binary_data)).reshape(*[int(shapeval) for shapeval in d['shape']]),axis=1)]\n",
    "print(\"Expected\",y[0:5].values.tolist(),\"Actual\",numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae72ec8d55aeb4773d9bab14ab14ec6c410f2dd8be83850b7c2732f479ead773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
