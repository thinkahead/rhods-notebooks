{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bc3ea-4ce3-49bf-bb1f-e209de8ca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
    "from codeflare_sdk.cluster.auth import TokenAuthentication\n",
    "from codeflare_sdk.job.jobs import DDPJobDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614daa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication object for oc user permissions\n",
    "auth = TokenAuthentication(\n",
    "    token = \"sha256~6b0qBf0X1S2e-IrV4mhtU1fLdwxlm70qbrsG5QK8jK0\",\n",
    "    server = \"https://api.mini2.mydomain.com:6443\",\n",
    "    skip_tls=True\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27f84c",
   "metadata": {},
   "source": [
    "Here, we want to define our cluster by specifying the resources we require for our batch workload. Below, we define our cluster object (which generates a corresponding AppWrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bc870-091f-4e11-9642-cba145710159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our cluster and submit appwrapper (reduce specs as desired)\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='mnisttest',\n",
    "    namespace='batch-mnist',\n",
    "    image=\"quay.io/thinkahead/base:ray2.1.0-py38-gpu-pytorch1.12.0cu117-20230419-1\",\n",
    "    min_worker=2,\n",
    "    max_worker=3,\n",
    "    min_cpus=8,\n",
    "    max_cpus=8,\n",
    "    min_memory=16,\n",
    "    max_memory=16,\n",
    "    gpu=1,\n",
    "    instascale=False # Can be set to false if scaling not needed\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eef53c",
   "metadata": {},
   "source": [
    "Next, we want to bring our cluster up, so we call the `up()` function below to submit our cluster AppWrapper yaml onto the MCAD queue, and begin the process of obtaining our resource cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0884bbc-c224-4ca0-98a0-02dfa09c2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring up the cluster\n",
    "cluster.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ebdfb",
   "metadata": {},
   "source": [
    "Now, we want to check on the status of our resource cluster, and wait until it is finally ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b4311-2e61-44c9-8225-87c2db11363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a55fe4",
   "metadata": {},
   "source": [
    "Let's quickly verify that the specs of the cluster are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd45bc5-03c0-4ae5-9ec5-dd1c30f1a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2c9b3",
   "metadata": {},
   "source": [
    "Now that our resource cluster is ready, we can directly submit our batch job (model training on two workers with four gpus each) to the cluster via torchx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6ccd6-a17e-413a-a0e4-65004fc35463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobdef = DDPJobDefinition(\n",
    "    name=\"mnisttest\",\n",
    "    script=\"mnist.py\",\n",
    "    #scheduler_args={\"requirements\": \"requirements.txt\"}\n",
    ")\n",
    "job = jobdef.submit(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff065051",
   "metadata": {},
   "source": [
    "Now we can go ahead and look at the status and logs of our batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0b0da-c22e-4142-b096-407ac8aebe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c1809-de72-4acf-b0f6-e67d345640f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8cd32",
   "metadata": {},
   "source": [
    "Finally, we bring our resource cluster down and release/terminate the associated resources, bringing everything back to the way it was before our cluster was brought up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36db0f-31f6-4373-9503-dc3c1c4c3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39a92f-a2d8-4ff2-b960-4aacba121251",
   "metadata": {},
   "source": [
    "# Fetch the Mnist_784 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b9443-c626-41a0-9686-44bdd217be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "X, y = fetch_openml('mnist_784', return_X_y=True, parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157aad9-3da1-4c93-ac1f-6d3182356c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name='mnist1' # torch.onnx.export\n",
    "#model_name='mnist2' # Pytorch Lightning model.to_onnx\n",
    "#model_name='mnist3' # torch.onnx.export with batch\n",
    "model_name='mnist4' # Pytorch Lightning model.to_onnx with batch\n",
    "\n",
    "model_file_name=model_name+\".onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db22506-bb64-4e68-b819-b3a40efef834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import numpy as np\n",
    "session = onnxruntime.InferenceSession(model_file_name, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "print(\"input name\", input_name)\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "print(\"input shape\", input_shape)\n",
    "input_type = session.get_inputs()[0].type\n",
    "print(\"input type\", input_type)\n",
    "print([i.name for i in session.get_outputs()])\n",
    "output_name = session.get_outputs()[0].name\n",
    "print(\"output name\", output_name)\n",
    "output_shape = session.get_outputs()[0].shape\n",
    "print(\"output shape\", output_shape)\n",
    "output_type = session.get_outputs()[0].type\n",
    "print(\"output type\", output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9d31a-d72b-4149-96f4-b757bdb010a1",
   "metadata": {},
   "source": [
    "# Batch request shape (batch_size,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0cd67-863d-4d4f-9cc6-15abb9fd264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=X[0:5]\n",
    "actual=y[0:5]\n",
    "arr=np.array(batch)\n",
    "result = session.run([i.name for i in session.get_outputs()], {input_name:(arr.reshape(len(batch),1,28,28).astype(np.float32))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acd7b2-0ae2-4ebd-b5bf-d598bc0a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(result[0],axis=1),actual.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a103da-571d-446e-a930-8f209c1ec8f1",
   "metadata": {},
   "source": [
    "# Single request shape (1,1,28,28) - Loop through all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646210-4ad0-4f57-9221-549e06e24fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in X.index:\n",
    "    arr=np.array(X.iloc[i])\n",
    "    result = session.run([i.name for i in session.get_outputs()], {input_name:(arr.reshape(1,*input_shape[1:]).astype(np.float32))})\n",
    "    expected=y.iloc[i]\n",
    "    actual=np.argmax(result)\n",
    "    if str(actual)!=expected: count+=1\n",
    "    #print(\"Expected\",expected,\"Actual\",str(actual)==expected)\n",
    "print('Failed percent:',count/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560e45f-e718-4f6b-8463-37a7236435dc",
   "metadata": {},
   "source": [
    "# Copy onnx model to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ceef17-48fc-4fcc-89bf-971b9cafa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from boto3 import session\n",
    "key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "session = boto3.session.Session(aws_access_key_id=key_id, aws_secret_access_key=secret_key)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=key_id, aws_secret_access_key=secret_key,endpoint_url=endpoint_url,verify=False)\n",
    "buckets=s3_client.list_buckets()\n",
    "for bucket in buckets['Buckets']: print(bucket['Name'])\n",
    "s3_client.upload_file(model_file_name, bucket['Name'],model_file_name)\n",
    "[item.get(\"Key\") for item in s3_client.list_objects_v2(Bucket=bucket['Name']).get(\"Contents\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fd588-8f58-417c-906e-c5a1e8e08fdb",
   "metadata": {},
   "source": [
    "Deploy the model in your Data Science project using RHODS UI under \"Models and model servers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a497a8-f137-4f0b-9227-0e72a1f8a0fc",
   "metadata": {},
   "source": [
    "# Submit HTTP REST request to the ModelMesh for a batch and receive response from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988c792-d0f4-451d-8254-bbd7cd0846b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mnist4\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "URL='http://modelmesh-serving.huggingface.svc.cluster.local:8008/v2/models/'+model_name+'/infer' # underscore characters are removed\n",
    "headers = {}\n",
    "payload = {\n",
    "        \"inputs\": [{ \"name\": \"input_0\", \"shape\": (5,1,28,28), \"datatype\": \"FP32\", \"data\": X.loc[0:4].values.flatten().tolist()}]\n",
    "    }\n",
    "#print(payload)\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "res = requests.post(URL, json=payload, headers=headers)\n",
    "print(res)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb8ec0-43b5-46a7-b6b3-d07908454528",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y[0:5].values.tolist()\n",
    "expected=np.argmax(np.array(res.json()['outputs'][0]['data']).reshape(res.json()['outputs'][0]['shape']),axis=1)\n",
    "print(actual,expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697e7f6-86d6-4810-a0be-25f3bd9ad3cb",
   "metadata": {},
   "source": [
    "# Submit HTTP REST request to the ModelMesh for single sample and receive response from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56387f1d-26b0-4b0c-b774-7a68c3123db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"mnist1\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "URL='http://modelmesh-serving.huggingface.svc.cluster.local:8008/v2/models/'+model_name+'/infer' # underscore characters are removed\n",
    "headers = {}\n",
    "payload = {\n",
    "        \"inputs\": [{ \"name\": \"input_0\", \"shape\": (1,1,28,28), \"datatype\": \"FP32\", \"data\": X.iloc[0].values.tolist()}]\n",
    "    }\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "res = requests.post(URL, json=payload, headers=headers)\n",
    "print(res)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9bfe1-5600-4571-82f8-3938159592a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected\",y.iloc[0],\"Actual\",np.argmax(res.json()['outputs'][0]['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786bde3-5d60-45ca-b1a2-fec960fa8129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae72ec8d55aeb4773d9bab14ab14ec6c410f2dd8be83850b7c2732f479ead773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
