{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9629c6-1715-4a22-aaf1-0ed9d90d50af",
   "metadata": {},
   "source": [
    "Original Source code from https://github.com/project-codeflare/codeflare-sdk/blob/main/demo-notebooks/guided-demos/4_gpt.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c05b69-4ce8-45ef-82d3-bacb2491bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
    "from codeflare_sdk.cluster.auth import TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f99bbd-9903-4d38-a4f2-223dec684ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication object for oc user permissions\n",
    "auth = TokenAuthentication(\n",
    "    token = \"sha256~QBcp_PWlBuBg7vy1GTQYZR-w6vRjubw488A9QvyiqsA\",\n",
    "    server = \"https://api.mini2.mydomain.com:6443\",\n",
    "    skip_tls=True\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566950c9-0696-4c8c-80b8-3c42d6172636",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(ClusterConfiguration(name='gptfttest', namespace='huggingface', min_worker=2, max_worker=3,\n",
    "    min_cpus=2, max_cpus=4, min_memory=8, max_memory=16, gpu=1, instascale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c8277-3b3b-4238-a786-a391a662fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f66ce-adaa-4709-b9cf-22417847e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e80ec2-6f44-4266-9108-1bc162ac5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk.cluster.cluster import list_all_queued\n",
    "list_all_queued(namespace=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fac218-2f22-428b-9228-137a4bb0e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5bd75-4230-4c7c-a9e2-0f247890e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk.job.jobs import DDPJobDefinition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c4ab1-374b-48c1-9293-1966524a19cf",
   "metadata": {},
   "source": [
    "The following example fine-tunes GPT-2 on the raw WikiText-2. The loss here is that of causal language modeling. Reference https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/README.md#gpt-2gpt-and-causal-language-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b419579-f213-4916-ba91-db9d777568e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_list = [\n",
    "    \"--model_name_or_path\", \"gpt2\",\n",
    "    \"--dataset_name\", \"wikitext\",\n",
    "    \"--dataset_config_name\", \"wikitext-2-raw-v1\",\n",
    "    \"--per_device_train_batch_size\", \"3\", # 3 works with 16GB GPU RAM\n",
    "    \"--per_device_eval_batch_size\", \"3\",\n",
    "    \"--do_train\",\n",
    "    \"--do_eval\",\n",
    "    \"--output_dir\", \"/tmp/test-clm\",\n",
    "    \"--overwrite_output_dir\",\n",
    "    \"--num_train_epochs\", \"3\" # default is 3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7c34f-e227-44c2-a4b1-a57c853ac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdef = DDPJobDefinition(\n",
    "    name=\"gpttest\",\n",
    "    script=\"run_clm.py\",\n",
    "    script_args=arg_list,\n",
    "    scheduler_args={\"requirements\": \"requirements.txt\"}\n",
    ")\n",
    "job = jobdef.submit(cluster)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19861a23-52b9-4cb0-87a3-b1ab31c4ce31",
   "metadata": {},
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d6198-9941-47e8-857f-9811830cc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960759f-2f46-4703-8523-4b804b98cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1a6b9-d9b3-49b7-b036-09f1d3569b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398d977-db24-46d0-a7d2-b4e9197808d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb97c1-4ca6-4996-b038-2e399a5849c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
